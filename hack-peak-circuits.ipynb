{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from qiskit import QuantumCircuit\n",
    "\n",
    "import quimb\n",
    "from qiskit_quimb import quimb_circuit\n",
    "from collections import Counter\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit = QuantumCircuit.from_qasm_file(\"P4_golden_mountain.qasm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(OrderedDict([('u3', 10240), ('cz', 5096)]), 48)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit.count_ops(), circuit.num_qubits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run MPS simulation\n",
    "\n",
    "Here we do a very low bond dimension simulation (relative to the number of qubits).\n",
    "\n",
    "The simulation error may be virtually 1, but that is OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_backend(x):\n",
    "    return torch.tensor(x, dtype=torch.complex64, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_bond=128, error~=1: 100%|##########| 15336/15336 [06:18<00:00, 40.52it/s]       \n"
     ]
    }
   ],
   "source": [
    "quimb_circuit = quimb_circuit(\n",
    "    circuit, \n",
    "    quimb_circuit_class=quimb.tensor.CircuitPermMPS,  # This will help with long range gates \n",
    "    to_backend=to_backend,  # This will make it run faster (on GPU) but is not required\n",
    "    max_bond=128,\n",
    "    cutoff=1e-12,\n",
    "    progbar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undo the qubit permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qubit_mapping = list(range(quimb_circuit.N))\n",
    "qubit_mapping = [quimb_circuit.qubits.index(q) for q in range(quimb_circuit.N)]\n",
    "qubit_mapping = [qubit_mapping[q] for q in qubit_mapping]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate samples\n",
    "\n",
    "We don't need to take a lot of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [''.join(bs[q] for q in qubit_mapping) for bs in quimb_circuit.sample(1000, seed=1234)]\n",
    "csamples = Counter(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('110000111011100100100110011011011001000001101000', 1),\n",
       " ('011111111101000111010111100100100000000001111110', 1),\n",
       " ('010001001010110001100010011111111010111101111101', 1),\n",
       " ('001111100100000101011000011101111011011100110000', 1),\n",
       " ('100101101111010011100111000110000100100110001100', 1),\n",
       " ('100110000100001101100110101100010010100001111001', 1),\n",
       " ('100000000110011000000001001110110100101111110001', 1),\n",
       " ('000001101100001010111000011100011110100010110010', 1),\n",
       " ('111111100111101000000110100001001011100000101010', 1),\n",
       " ('110001010001100011100110101001111110110111111011', 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(csamples.most_common())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distill peak bitstring\n",
    "\n",
    "Distillation can be done by methods ranging from sophisticated clustering to just majority voting.\n",
    "\n",
    "For these circuits I found it was enough to just do voting.\n",
    "\n",
    "The bit probabilities can tell how \"confident\" we are in the bitstring. If they are all close to 0.5, try increasing the bond dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45 , 0.604, 0.521, 0.584, 0.563, 0.494, 0.381, 0.354, 0.365,\n",
       "       0.569, 0.456, 0.404, 0.42 , 0.411, 0.611, 0.37 , 0.337, 0.427,\n",
       "       0.45 , 0.3  , 0.217, 0.633, 0.562, 0.357, 0.514, 0.425, 0.579,\n",
       "       0.631, 0.578, 0.538, 0.548, 0.589, 0.446, 0.382, 0.626, 0.43 ,\n",
       "       0.593, 0.363, 0.395, 0.417, 0.306, 0.596, 0.595, 0.576, 0.562,\n",
       "       0.546, 0.527, 0.485])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bit_probs = np.array([[int(s) for s in ss] for ss in samples]).mean(axis=0)\n",
    "bit_probs  # These are the individual bit probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voted_bitstring = \"\".join(str(i) for i in (bit_probs > 0.5).astype(int).tolist())\n",
    "voted_bitstring  # Run this to see the answer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output bitstring may not even be in the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voted_bitstring in csamples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
